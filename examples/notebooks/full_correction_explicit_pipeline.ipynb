{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACETpy Full Correction Workflow (Explicit Pipeline Syntax)\n",
    "\n",
    "This tutorial builds the full correction workflow manually with `Pipeline([...])`, so you can see and control every processor step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from facet import (\n",
    "    AASCorrection,\n",
    "    CutAcquisitionWindow,\n",
    "    DownSample,\n",
    "    EDFExporter,\n",
    "    HighPassFilter,\n",
    "    Loader,\n",
    "    LowPassFilter,\n",
    "    MedianArtifactCalculator,\n",
    "    MetricsReport,\n",
    "    Pipeline,\n",
    "    RMSCalculator,\n",
    "    RMSResidualCalculator,\n",
    "    RawPlotter,\n",
    "    SNRCalculator,\n",
    "    TriggerAligner,\n",
    "    TriggerDetector,\n",
    "    UpSample,\n",
    "    PasteAcquisitionWindow,\n",
    ")\n",
    "\n",
    "try:\n",
    "    from facet import PCACorrection\n",
    "except ImportError:\n",
    "    PCACorrection = None\n",
    "\n",
    "project_root = Path.cwd()\n",
    "if not (project_root / \"examples\").exists() and (project_root.parent / \"examples\").exists():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "input_file = project_root / \"examples\" / \"datasets\" / \"NiazyFMRI.edf\"\n",
    "output_dir = project_root / \"output\" / \"notebooks\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = output_dir / \"corrected_explicit_pipeline.edf\"\n",
    "plot_file = output_dir / \"explicit_pipeline_before_after.png\"\n",
    "\n",
    "print(f\"Input file: {input_file}\")\n",
    "assert input_file.exists(), f\"Missing dataset: {input_file}\"\n",
    "print(f\"PCACorrection available: {PCACorrection is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Core Correction Steps\n",
    "\n",
    "These processors cover the core sequence: load, detect triggers, isolate acquisition, high-pass filter, upsample, align triggers, and perform AAS artifact subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = [\n",
    "    Loader(path=str(input_file), preload=True, artifact_to_trigger_offset=-0.005),\n",
    "    TriggerDetector(regex=r\"\\\\b1\\\\b\"),\n",
    "    CutAcquisitionWindow(),\n",
    "    HighPassFilter(freq=1.0),\n",
    "    UpSample(factor=10),\n",
    "    TriggerAligner(ref_trigger_index=0, upsample_for_alignment=False),\n",
    "    AASCorrection(window_size=30, correlation_threshold=0.975, realign_after_averaging=True),\n",
    "]\n",
    "\n",
    "print(f\"Core steps configured: {len(processors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Add Optional PCA Residual Cleanup\n",
    "\n",
    "PCA correction can remove structured residual artifact after AAS. This cell adds it only when available in the current installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PCACorrection is not None:\n",
    "    processors.append(PCACorrection(n_components=0.95, hp_freq=1.0))\n",
    "    print(\"Added PCACorrection step.\")\n",
    "else:\n",
    "    print(\"PCACorrection unavailable; continuing without PCA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add Reconstruction, Evaluation, and Export\n",
    "\n",
    "After correction, we return to original sampling rate, paste acquisition windows back, low-pass filter, compute quality metrics, create a comparison plot, and export EDF output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors.extend([\n",
    "    DownSample(factor=10),\n",
    "    PasteAcquisitionWindow(),\n",
    "    LowPassFilter(freq=70.0),\n",
    "    SNRCalculator(),\n",
    "    RMSCalculator(),\n",
    "    RMSResidualCalculator(),\n",
    "    MedianArtifactCalculator(),\n",
    "    MetricsReport(),\n",
    "    RawPlotter(\n",
    "        mode=\"matplotlib\",\n",
    "        channel=\"Fp1\",\n",
    "        start=25.0,\n",
    "        duration=20.0,\n",
    "        overlay_original=True,\n",
    "        show=False,\n",
    "        auto_close=True,\n",
    "        save_path=str(plot_file),\n",
    "        title=\"Explicit Pipeline Workflow: Before vs After\",\n",
    "    ),\n",
    "    EDFExporter(path=str(output_file), overwrite=True),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(processors, name=\"Explicit Full Correction Workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Inspect Final Processor Order\n",
    "\n",
    "Printing the step order helps verify exactly what will run before executing the full workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, processor in enumerate(pipeline.processors, start=1):\n",
    "    print(f\"{idx:02d}. {processor.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Execute the Full Pipeline\n",
    "\n",
    "This runs all configured processors in sequence and returns a `PipelineResult` with runtime and quality metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.run()\n",
    "result.print_summary()\n",
    "result.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Inspect Context and Artifacts\n",
    "\n",
    "The final context contains processed data, trigger metadata, and processing history for debugging and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = result.context\n",
    "n_triggers = len(ctx.get_triggers()) if ctx.get_triggers() is not None else 0\n",
    "\n",
    "print(f\"Channels: {ctx.get_n_channels()}\")\n",
    "print(f\"Triggers: {n_triggers}\")\n",
    "print(f\"History steps: {len(ctx.get_history())}\")\n",
    "print(f\"Output exists: {output_file.exists()}\")\n",
    "print(f\"Plot exists: {plot_file.exists()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
