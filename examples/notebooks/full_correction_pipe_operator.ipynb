{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACETpy Full Correction Workflow (Pipe Operator Syntax)\n",
    "\n",
    "This tutorial runs the full correction workflow using `ProcessingContext | Processor` chaining.\n",
    "\n",
    "The pipe style is useful in notebooks because each stage can be inspected and modified interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from facet import (\n",
    "    AASCorrection,\n",
    "    CutAcquisitionWindow,\n",
    "    DownSample,\n",
    "    EDFExporter,\n",
    "    HighPassFilter,\n",
    "    LowPassFilter,\n",
    "    MedianArtifactCalculator,\n",
    "    MetricsReport,\n",
    "    RMSCalculator,\n",
    "    RMSResidualCalculator,\n",
    "    RawPlotter,\n",
    "    SNRCalculator,\n",
    "    TriggerAligner,\n",
    "    TriggerDetector,\n",
    "    UpSample,\n",
    "    PasteAcquisitionWindow,\n",
    "    load,\n",
    ")\n",
    "\n",
    "try:\n",
    "    from facet import PCACorrection\n",
    "except ImportError:\n",
    "    PCACorrection = None\n",
    "\n",
    "project_root = Path.cwd()\n",
    "if not (project_root / \"examples\").exists() and (project_root.parent / \"examples\").exists():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "input_file = project_root / \"examples\" / \"datasets\" / \"NiazyFMRI.edf\"\n",
    "output_dir = project_root / \"output\" / \"notebooks\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = output_dir / \"corrected_pipe_operator.edf\"\n",
    "plot_file = output_dir / \"pipe_operator_before_after.png\"\n",
    "\n",
    "print(f\"Input file: {input_file}\")\n",
    "assert input_file.exists(), f\"Missing dataset: {input_file}\"\n",
    "print(f\"PCACorrection available: {PCACorrection is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Recording into a ProcessingContext\n",
    "\n",
    "`load(...)` creates the initial context object that will be passed through all later pipe operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = load(str(input_file), preload=True, artifact_to_trigger_offset=-0.005)\n",
    "print(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Detect Triggers and Prepare for Correction\n",
    "\n",
    "This stage detects MR triggers, cuts acquisition windows, removes low-frequency drift, upsamples for timing precision, and aligns trigger positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = (\n",
    "    ctx\n",
    "    | TriggerDetector(regex=r\"\\\\b1\\\\b\")\n",
    "    | CutAcquisitionWindow()\n",
    "    | HighPassFilter(freq=1.0)\n",
    "    | UpSample(factor=10)\n",
    "    | TriggerAligner(ref_trigger_index=0, upsample_for_alignment=False)\n",
    ")\n",
    "\n",
    "n_triggers = len(ctx.get_triggers()) if ctx.get_triggers() is not None else 0\n",
    "print(f\"Detected triggers: {n_triggers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Apply Main Artifact Correction\n",
    "\n",
    "AAS (`Averaged Artifact Subtraction`) is the main correction method. If available, PCA is applied after AAS to remove structured residual artifact components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = ctx | AASCorrection(window_size=30, correlation_threshold=0.975, realign_after_averaging=True)\n",
    "\n",
    "if PCACorrection is not None:\n",
    "    ctx = ctx | PCACorrection(n_components=0.95, hp_freq=1.0)\n",
    "    print(\"Applied PCACorrection.\")\n",
    "else:\n",
    "    print(\"Skipped PCA (PCACorrection unavailable).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Reconstruct Final Signal Domain\n",
    "\n",
    "After correction at high sampling rate, this stage downsamples back, restores cut acquisition windows, and applies low-pass filtering for final cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = (\n",
    "    ctx\n",
    "    | DownSample(factor=10)\n",
    "    | PasteAcquisitionWindow()\n",
    "    | LowPassFilter(freq=70.0)\n",
    ")\n",
    "\n",
    "print(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compute Quality Metrics and Save Comparison Plot\n",
    "\n",
    "These processors calculate quality indicators (SNR and RMS-based metrics), print a report, and store a before/after visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = (\n",
    "    ctx\n",
    "    | SNRCalculator()\n",
    "    | RMSCalculator()\n",
    "    | RMSResidualCalculator()\n",
    "    | MedianArtifactCalculator()\n",
    "    | MetricsReport(name=\"Pipe Operator Workflow Metrics\")\n",
    "    | RawPlotter(\n",
    "        mode=\"matplotlib\",\n",
    "        channel=\"Fp1\",\n",
    "        start=25.0,\n",
    "        duration=20.0,\n",
    "        overlay_original=True,\n",
    "        show=False,\n",
    "        auto_close=True,\n",
    "        save_path=str(plot_file),\n",
    "        title=\"Pipe Operator Workflow: Before vs After\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Export Corrected Recording\n",
    "\n",
    "This writes the final corrected EEG to EDF while keeping the updated context available for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = ctx | EDFExporter(path=str(output_file), overwrite=True)\n",
    "print(f\"Exported: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Inspect Final Results\n",
    "\n",
    "Finally, inspect key metrics, processing history, and file existence checks to verify the workflow completed as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ctx.metadata.custom.get(\"metrics\", {})\n",
    "print(\"Key metrics:\")\n",
    "for key in (\"snr\", \"rms_ratio\", \"rms_residual\", \"median_artifact\"):\n",
    "    if key in metrics:\n",
    "        print(f\"  {key}: {metrics[key]}\")\n",
    "\n",
    "history = ctx.get_history()\n",
    "print(f\"\\nRecorded processing steps: {len(history)}\")\n",
    "for step in history[:8]:\n",
    "    print(f\"  - {step.name}\")\n",
    "if len(history) > 8:\n",
    "    print(\"  ...\")\n",
    "\n",
    "print(f\"\\nOutput exists: {output_file.exists()}\")\n",
    "print(f\"Plot exists: {plot_file.exists()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
